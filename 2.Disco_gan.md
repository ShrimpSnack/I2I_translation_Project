# Disco gan
: 데이터들의 관계를 설명하는데에는 많은 근거가 필요하다. 또한 관계를 자동으로 발견하는 것은 매우 어렵다. 따라서 페어링되지 않은 데이터에서 교차 도메인 관계를 발견할 수 있도록 한다.

- Disco_gan : 서로 다른 도메인간의 관계를 발견하는 방법을 학습하는 GAN기반 방법이다.
- 발견된 관계를 사용하여 이 네트워크는 방향 및 얼굴 정체성과 같은 주요 속성을 보존하면서 한 도메인에서 다른 도메인으로 스타일을 성공적으로 전송한다.

# introduction
- 개념, 대상 또는 사람이 연결되는 서로 다른 두 영역간의 관계는 언제나 존재한다.
- domain간의 관계는 종종 자연스러운 일이다.
- 예를들어 영어문장과 프랑스어로 번역된 문장 사이의 관계를 인식가능하다.
- 또한 같은 스타일의 바지 또는 신발, 외투를 선택할 수 있다.
- 한 domain에서 다른 domain으로의 mapping 함수를 찾는 것 = 다른 domain의 이미지가 주어지면 한 domain에서 이미지를 생성하는 것 으로도 생각할 수 있다.
- 최근 연구에서는 쌍을 이룬 데이터를 사용한다. 

- 이전 연구의 문제점
  - 명시적으로 쌍을 이룬 데이터는 거의 사용불가하며 라벨링에는 많은 노동을 필요로 한다.
  - 또한, 한 domain에 해당 이미지가 없거나 여러개의 최적의 후보가 있을 경우 페어링이 어렵다.
  - Pix2Pix는 input data와 output(정답) data가 필요하다. ( supervised learning )
  - 따라서, paired dataset이 필요한 Pix2Pix의 문제점을 해결하고자함\
  ![image](https://user-images.githubusercontent.com/70633080/110598197-d316ec00-81c4-11eb-9c39-f0e7860f0e2a.png)

 - 본 연구의 목적
    - **Paired Data를 얻기 힘든 경우에 대해서도 style transfer를 가능하게 한다.**
    - 같은 자세의 말과 얼룩말이 아니라 단순히 말과 얼룩말의 이미지 만으로 학습이 가능하다.
    - Cycle gan도 이와 유사하다.

# Model
- Disco_gan 구조\
![image](https://user-images.githubusercontent.com/70633080/110601936-cf856400-81c8-11eb-8b4e-2531827faefc.png)

- G는 generator, D는 discriminator를 의미한다.
- A는 말, B는 얼룩말을 의미한다.
- G_AB : 말을 input으로 받아 얼룩말데이터를 생성하도록 학습
- D_B : 실제 얼룩말과 G_AB의 가짜얼룩말을 구분하도록 학습
- 이때, G_AB는 input과 같은 자세의 얼룩말을 생성하진 못한다. (자세를 알려주지 않았기 때문)
- 따라서 또다른 generator인 G_BA가 있다.
- G_BA : 가짜얼룩말을 다시 말로 바꾸는 generator 
  - G_BA는 input과 동일해야한다. 따라서 loss에 consistency loss를 추가함.
  
- **Consistency loss** : input과 G_BA의 loss를 전체 loss에 추가
  - Disco gan의 경우 L2-loss를 , Ctcle gan의 경우 L1-loss를 사용한다.
  - 이렇게 되면 Disco gan은 함부로 아무 얼룩말 이미지로 바꿀 수 없다. (원본으로 돌아올 것까지 생각해야하기 때문)
  - Disco gan은 input의 말이미지에서 얼룩말처럼 보이게 만드는데 필요한 최소한의 부분만 수정하게 된다.
  - 굳이 수정이 필요하지 않은 자세, 주변 배경 등이 유지 되는 것이다.

![image](https://user-images.githubusercontent.com/70633080/110601565-6f8ebd80-81c8-11eb-91e9-fd33070e562d.png)
- 다음으로 G_BA에는 generator이지만 생성한 이미지가 실제 이미지와 구분될 수 없어야한다는 loss가 존재하지 않는다.
- 또한, 말 -> 얼룩말 그리고 얼룩말 -> 말 인 대칭적인 구조여야 안정적인 학습이 가능하다.
- 따라서 반대의 구조 역시 동시에 학습한다.

## Model structure
- Disco gan의 Generator\
![image](https://user-images.githubusercontent.com/70633080/110602431-5afef500-81c9-11eb-9dcf-67921bc66f6b.png)

- Disco gan의 Discriminator\
![image](https://user-images.githubusercontent.com/70633080/110602502-6ce09800-81c9-11eb-94d8-22285ea98be3.png)

## Loss
- 최종 loss는 아래와 같다.\
![image](https://user-images.githubusercontent.com/70633080/110602302-360a8200-81c9-11eb-8fb2-fe8a9f9dbfe1.png)

# Result
- 왼 : input , 오 : output\
![image](https://user-images.githubusercontent.com/70633080/110602648-8e418400-81c9-11eb-81f5-3e6f2c42b47e.png)
